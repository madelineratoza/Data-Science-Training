{"title":"What is Data Science?","markdown":{"yaml":{"title":"What is Data Science?","format":"html"},"headingText":"Data Skill Set Definitions","containsRefs":false,"markdown":"\n\nData science is often described as a combination of mathematics, statistics, programming, advanced analytics, artificial intelligence, and machine learning, combined with subject matter expertise to uncover actionable insights.\n\nWhile this definition is technically accurate, it is not always helpful.\n\nFor most people working in education, healthcare, or research, the more useful question is not: **“What is data science?”**\n\nBut rather:\\\n**“What kinds of skills are needed to work with data well?”**\n\n\nData science is a broad ecosystem of skills. No one person has all of them, and most roles overlap in practice. It is helpful to think in terms of types of work, not job titles.\n\n|  |  |  |\n|------------------------|------------------------|------------------------|\n| **Data Engineering:** | **Data Science:** | **Data Analysis:** |\n| This work focuses on how data are stored, structured, and maintained. It includes managing hardware and storage systems, as well as writing code to handle messy or unstructured data. | This work often focuses on software development, large-scale datasets, and cloud-based systems. It frequently involves advanced modeling and machine learning. | **This is where many educators and researchers already operate.** It includes cleaning and organizing data, analyzing patterns and outcomes, creating visualizations, and communicating results clearly in writing and presentations. |\n\n## \"Big Data\" is not the point\n\nThe term “big data” is often used to describe massive datasets such as search engine queries or real-time commercial analytics. Most people working in academic, educational, or clinical settings will never interact with data at this scale.\n\nHowever, data science tools are still valuable even when datasets are small.\n\nEven if all your data fits on a single screen, modern data workflows can reduce errors, improve consistency, make analyses faster, and allow others to understand what was done.\n\n## The Data Ecosystem Problem\n\nData rarely live in one place forever. Over the life of a project, data may be collected in one system, cleaned in another, analyzed in multiple versions, revised in response to feedback, and shared with collaborators or reviewers.\n\nEach transition creates opportunities for data loss, version confusion, and error.\n\nReproducible workflows help by creating a clear, documented path from raw data to final results.\n\n## Reproducibility: Controlling What We Can\n\nReproducibility means that the same input data and the same analysis steps produce the same output every time.\n\nIn practice, this means **data are preserved in their original form**, analysis steps are documented, and results can be regenerated by re-running the analysis.\n\nWhile we cannot control all sources of variation, we can control whether our workflows are reproducible.\n\n**WHAT THIS MEANS FOR EXCEL USERS:**\\\nExcel is a powerful and familiar tool, and it often plays an important role in data workflows. Moving toward reproducible workflows does not mean abandoning Excel immediately.\n\nInstead, it means being intentional about how data are entered and edited, reducing manual undocumented steps, creating clear transitions between data cleaning, analysis, and reporting, and using tools that allow analyses to be repeated without starting over.\n\n## Basic concepts & terminology\n\n::: panel-tabset\n## Data Frame\n\nA data frame is a table of data where each row represents an observation (such as a student, course, or exam) and each column represents a variable. Data frames are the primary way data are organized in R and are similar in structure to Excel spreadsheets when those spreadsheets are used consistently.\n\nHowever, many common Excel formatting practices prevent a sheet from functioning as a true data frame. Merged cells, blank rows or columns, embedded totals, and missing values used for visual spacing all break the row-by-column structure that data analysis tools rely on. While these formats may look clear to a human reader, they make it difficult for software to reliably interpret the data.\n\nThis guide emphasizes structuring data so that it behaves as a data frame, even when it is created or viewed in Excel.\n\n## Variable\n\nA variable is a single column in a dataset that contains a specific type of information, such as a score, term, pathway, or outcome.\n\n## Data labels\n\nData labels are names or categories used to describe variables or values within a dataset. Clear, consistent labels make it easier to understand what the data represent and reduce the risk of misinterpretation during analysis.\n\nIn more complex projects, data labels are often supported by a data dictionary. A data dictionary is a separate document that defines each variable, explains how values are coded, and provides context for how the data were collected or generated. While data dictionaries are not required for every project, they are especially helpful when datasets are shared, revisited over time, or used by multiple people.\n\nThis guide introduces simple labeling practices and shows how even lightweight documentation can improve clarity and reproducibility.\n\n## Logic\n\nLogic refers to the rules used to make decisions within data analysis. These rules determine which data are included, excluded, grouped, or summarized based on specific conditions.\n\nIn academic program and assessment work, logic is often used to answer questions such as which students belong to a specific cohort, which exam scores fall within a given term, or which outcomes meet a defined threshold. For example, logic can be used to select exam grades from a particular term, group those grades by cohort, and then summarize or visualize the results in a chart.\n\nUsing explicit logical rules in code makes these decisions transparent and repeatable. Instead of manually filtering or sorting data, the logic used to create a figure or summary is documented and can be applied consistently across terms or updated datasets.\n\n## Code\n\nCode is a written set of instructions that tells a computer exactly what steps to perform on data. These instructions can include importing data, selecting specific values, performing calculations, creating summaries, and generating visualizations.\n\nThere are many programming languages used for data analysis, each with different strengths. Common examples include R, Python, and SQL. No single language is “best” in all situations, and learning one language makes it easier to learn others over time.\n\nFor the purposes of this guide, R is used because it is free, widely used in academic and research settings, and well suited for data analysis and visualization. R allows analysis steps to be written clearly and run again on updated data, supporting reproducible workflows without requiring advanced programming experience.\n\nThis guide focuses on using small, readable pieces of code to document data analysis decisions rather than on complex or highly technical programming.\n\n## Reproducibility\n\nReproducibility means that the same data and the same analysis steps produce the same results every time the analysis is run. In a reproducible workflow, data are preserved in their original form, analysis steps are documented using code, and results can be regenerated simply by re-running the analysis.\n\nFor academic programs that review data term-by-term or annually, reproducibility is especially powerful because it improves efficiency over time. Once an analysis workflow is written, the same code can be reused with new data each term or year, eliminating the need to rebuild tables, charts, or reports from scratch. This reduces manual effort, minimizes errors introduced by repeated copying or filtering, and ensures that comparisons across time are based on consistent methods.\n\nReproducible workflows also make it easier to respond to new questions or reporting requests. Because the logic of the analysis is explicit, adjustments can be made quickly without undoing prior work. Over time, this allows programs to shift from reactive data processing to more intentional, longitudinal analysis.\n:::\n","srcMarkdownNoYaml":"\n\nData science is often described as a combination of mathematics, statistics, programming, advanced analytics, artificial intelligence, and machine learning, combined with subject matter expertise to uncover actionable insights.\n\nWhile this definition is technically accurate, it is not always helpful.\n\nFor most people working in education, healthcare, or research, the more useful question is not: **“What is data science?”**\n\nBut rather:\\\n**“What kinds of skills are needed to work with data well?”**\n\n## Data Skill Set Definitions\n\nData science is a broad ecosystem of skills. No one person has all of them, and most roles overlap in practice. It is helpful to think in terms of types of work, not job titles.\n\n|  |  |  |\n|------------------------|------------------------|------------------------|\n| **Data Engineering:** | **Data Science:** | **Data Analysis:** |\n| This work focuses on how data are stored, structured, and maintained. It includes managing hardware and storage systems, as well as writing code to handle messy or unstructured data. | This work often focuses on software development, large-scale datasets, and cloud-based systems. It frequently involves advanced modeling and machine learning. | **This is where many educators and researchers already operate.** It includes cleaning and organizing data, analyzing patterns and outcomes, creating visualizations, and communicating results clearly in writing and presentations. |\n\n## \"Big Data\" is not the point\n\nThe term “big data” is often used to describe massive datasets such as search engine queries or real-time commercial analytics. Most people working in academic, educational, or clinical settings will never interact with data at this scale.\n\nHowever, data science tools are still valuable even when datasets are small.\n\nEven if all your data fits on a single screen, modern data workflows can reduce errors, improve consistency, make analyses faster, and allow others to understand what was done.\n\n## The Data Ecosystem Problem\n\nData rarely live in one place forever. Over the life of a project, data may be collected in one system, cleaned in another, analyzed in multiple versions, revised in response to feedback, and shared with collaborators or reviewers.\n\nEach transition creates opportunities for data loss, version confusion, and error.\n\nReproducible workflows help by creating a clear, documented path from raw data to final results.\n\n## Reproducibility: Controlling What We Can\n\nReproducibility means that the same input data and the same analysis steps produce the same output every time.\n\nIn practice, this means **data are preserved in their original form**, analysis steps are documented, and results can be regenerated by re-running the analysis.\n\nWhile we cannot control all sources of variation, we can control whether our workflows are reproducible.\n\n**WHAT THIS MEANS FOR EXCEL USERS:**\\\nExcel is a powerful and familiar tool, and it often plays an important role in data workflows. Moving toward reproducible workflows does not mean abandoning Excel immediately.\n\nInstead, it means being intentional about how data are entered and edited, reducing manual undocumented steps, creating clear transitions between data cleaning, analysis, and reporting, and using tools that allow analyses to be repeated without starting over.\n\n## Basic concepts & terminology\n\n::: panel-tabset\n## Data Frame\n\nA data frame is a table of data where each row represents an observation (such as a student, course, or exam) and each column represents a variable. Data frames are the primary way data are organized in R and are similar in structure to Excel spreadsheets when those spreadsheets are used consistently.\n\nHowever, many common Excel formatting practices prevent a sheet from functioning as a true data frame. Merged cells, blank rows or columns, embedded totals, and missing values used for visual spacing all break the row-by-column structure that data analysis tools rely on. While these formats may look clear to a human reader, they make it difficult for software to reliably interpret the data.\n\nThis guide emphasizes structuring data so that it behaves as a data frame, even when it is created or viewed in Excel.\n\n## Variable\n\nA variable is a single column in a dataset that contains a specific type of information, such as a score, term, pathway, or outcome.\n\n## Data labels\n\nData labels are names or categories used to describe variables or values within a dataset. Clear, consistent labels make it easier to understand what the data represent and reduce the risk of misinterpretation during analysis.\n\nIn more complex projects, data labels are often supported by a data dictionary. A data dictionary is a separate document that defines each variable, explains how values are coded, and provides context for how the data were collected or generated. While data dictionaries are not required for every project, they are especially helpful when datasets are shared, revisited over time, or used by multiple people.\n\nThis guide introduces simple labeling practices and shows how even lightweight documentation can improve clarity and reproducibility.\n\n## Logic\n\nLogic refers to the rules used to make decisions within data analysis. These rules determine which data are included, excluded, grouped, or summarized based on specific conditions.\n\nIn academic program and assessment work, logic is often used to answer questions such as which students belong to a specific cohort, which exam scores fall within a given term, or which outcomes meet a defined threshold. For example, logic can be used to select exam grades from a particular term, group those grades by cohort, and then summarize or visualize the results in a chart.\n\nUsing explicit logical rules in code makes these decisions transparent and repeatable. Instead of manually filtering or sorting data, the logic used to create a figure or summary is documented and can be applied consistently across terms or updated datasets.\n\n## Code\n\nCode is a written set of instructions that tells a computer exactly what steps to perform on data. These instructions can include importing data, selecting specific values, performing calculations, creating summaries, and generating visualizations.\n\nThere are many programming languages used for data analysis, each with different strengths. Common examples include R, Python, and SQL. No single language is “best” in all situations, and learning one language makes it easier to learn others over time.\n\nFor the purposes of this guide, R is used because it is free, widely used in academic and research settings, and well suited for data analysis and visualization. R allows analysis steps to be written clearly and run again on updated data, supporting reproducible workflows without requiring advanced programming experience.\n\nThis guide focuses on using small, readable pieces of code to document data analysis decisions rather than on complex or highly technical programming.\n\n## Reproducibility\n\nReproducibility means that the same data and the same analysis steps produce the same results every time the analysis is run. In a reproducible workflow, data are preserved in their original form, analysis steps are documented using code, and results can be regenerated simply by re-running the analysis.\n\nFor academic programs that review data term-by-term or annually, reproducibility is especially powerful because it improves efficiency over time. Once an analysis workflow is written, the same code can be reused with new data each term or year, eliminating the need to rebuild tables, charts, or reports from scratch. This reduces manual effort, minimizes errors introduced by repeated copying or filtering, and ensures that comparisons across time are based on consistent methods.\n\nReproducible workflows also make it easier to respond to new questions or reporting requests. Because the logic of the analysis is explicit, adjustments can be made quickly without undoing prior work. Over time, this allows programs to shift from reactive data processing to more intentional, longitudinal analysis.\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"What is Data Science?.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.27","theme":"darkly","title":"What is Data Science?"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}